{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3613jvsc74a57bd0005fd61b403ca84a45cc259c31144f5d9e05c700f61a6b3e04c5151a6b4691b5",
   "display_name": "Python 3.6.13 64-bit ('ai': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Convolutional Nueral Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "source": [
    "## Data Processing "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Training Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training set images augmentation to avoid overfitting \n",
    "\n",
    "train_datagen = ImageDataGenerator (\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2 ,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "source": [
    "### Testing Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen =  ImageDataGenerator ( rescale = 1./255)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory ('dataset/test_set',\n",
    "                                            target_size = (64,64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode= 'binary'\n",
    "    )"
   ]
  },
  {
   "source": [
    "## Building The CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Initializing the CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "\n",
    "cnn = Sequential() "
   ]
  },
  {
   "source": [
    "#### Layers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st Convolutional Layer\n",
    "cnn.add(Conv2D(filters=32, kernel_size = 3, activation =\"relu\", input_shape=(64,64,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling \n",
    "cnn.add(MaxPool2D(pool_size = 2, strides = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd Convolutional Layer\n",
    "cnn.add(Conv2D(filters=32, kernel_size = 3, activation =\"relu\"))\n",
    "\n",
    "# 2nd Pooling layers\n",
    "cnn.add(MaxPool2D(pool_size = 2, strides = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening Layer\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full COnnection\n",
    "cnn.add(Dense(units = 128, activation = \"relu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Output Layer\n",
    "cnn.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "source": [
    "## Training The CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    " #### Compiling the CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimzer = \"adma\", loss=\"binary_crossentropy\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on training set\n",
    "\n",
    "cnn.fit(training_set, )"
   ]
  }
 ]
}